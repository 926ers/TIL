latency:  하나의 데이터 패킷이 한 지점에서 다른 지점으로 전송되어 이에 소요되는 시간

네트워크 하드웨어 기술, 운영 시스템 등의 문제

bandwidth: 단위 시간에서 한 지점에서 다른 지점으로 전송할 수 있는 최대 데이터 (bps)

#### 레이턴시 줄이는 법

네트워크 인프라 개선

클라이언트와 서버의 거리(CDN)

병목 현상 파악 및 해결(DB? was?)

브라우저 캐시

적은 리소스 로드(spring webflux-> 비동기 논블로킹 i/o)

HTTP/2 -> 압축



```
http2는 왜 레이턴시가 낮은가요? 
```

HTTP/2가 레이턴시가 낮은 이유는 여러 가지 개선된 기술과 메커니즘 덕분입니다. HTTP/1.1에 비해 HTTP/2는 다음과 같은 기능을 통해 네트워크 레이턴시를 줄입니다:

### 1. 멀티플렉싱 (Multiplexing)

- **멀티플렉싱**은 단일 TCP 연결을 통해 여러 요청과 응답을 동시에 보내고 받을 수 있게 합니다. 이는 HTTP/1.1에서 발생하는 '헤드 오브 라인 블로킹' 문제를 해결합니다.
- HTTP/1.1에서는 하나의 연결에서 한 번에 하나의 요청만 처리할 수 있었고, 하나의 요청이 완료되기 전까지 다른 요청은 대기해야 했습니다. HTTP/2에서는 이러한 대기 시간이 사라져 응답 속도가 빨라집니다.

### 2. 헤더 압축 (Header Compression)

- **HPACK 압축**을 사용하여 HTTP 헤더의 크기를 줄입니다. HTTP/1.1에서는 각 요청마다 반복되는 헤더 정보가 전송되지만, HTTP/2에서는 이를 압축하여 전송합니다.
- 헤더의 크기가 줄어들면 전송해야 하는 데이터 양이 감소하여 레이턴시가 줄어듭니다.

### 3. 서버 푸시 (Server Push)

- **서버 푸시**는 클라이언트가 요청하지 않은 리소스도 서버가 미리 전송할 수 있는 기능입니다. 예를 들어, HTML 페이지를 요청할 때 그 페이지에 필요한 CSS, JavaScript 파일 등을 미리 전송할 수 있습니다.
- 클라이언트가 리소스를 요청하기 전에 필요한 리소스를 받을 수 있어 페이지 로드 시간이 단축됩니다.

### 4. 스트림 우선순위 (Stream Prioritization)

- **스트림 우선순위** 기능을 통해 클라이언트는 요청의 중요도에 따라 우선순위를 지정할 수 있습니다. 서버는 이를 바탕으로 중요한 요청을 먼저 처리하여 응답할 수 있습니다.
- 중요한 리소스를 빠르게 받을 수 있어 사용자 경험이 개선됩니다.

### 5. 단일 연결 유지 (Single Connection)

- HTTP/2는 단일 TCP 연결을 통해 모든 요청을 처리하므로, 새로운 연결을 설정하는 데 소요되는 시간(TCP 핸드셰이크 및 TLS 설정 시간)이 절약됩니다.
- 연결 설정과 종료에 드는 오버헤드가 줄어들어 레이턴시가 감소합니다.

### 6. 효율적인 네트워크 자원 사용

- HTTP/2는 연결 수를 줄이고, 네트워크 자원을 효율적으로 사용합니다. 이는 TCP 연결의 설정 및 유지 비용을 절감하고, 네트워크 병목 현상을 완화합니다.
- 네트워크 혼잡을 줄여 더 빠른 데이터 전송이 가능해집니다.

이러한 이유들로 인해 HTTP/2는 HTTP/1.1에 비해 레이턴시가 낮고, 빠른 웹 페이지 로딩과 더 나은 사용자 경험을 제공합니다.
